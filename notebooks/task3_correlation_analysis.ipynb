{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Task 3: Correlation between News Sentiment and Stock Movement\n",
        "\n",
        "This notebook performs correlation analysis between financial news sentiment and stock price movements.\n",
        "\n",
        "## Analysis Components:\n",
        "1. **Data Preparation**: Load and align news and stock data by dates\n",
        "2. **Sentiment Analysis**: Analyze sentiment of news headlines using NLTK/TextBlob\n",
        "3. **Stock Returns Calculation**: Calculate daily percentage changes in stock prices\n",
        "4. **Correlation Analysis**: Statistical correlation between sentiment and returns\n",
        "5. **KPIs**: Sentiment analysis accuracy and correlation strength metrics\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Setup and Imports\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "import os\n",
        "sys.path.append('../scripts')\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set plotting style\n",
        "plt.style.use('seaborn-v0_8')\n",
        "sns.set_palette(\"husl\")\n",
        "\n",
        "# Import custom modules\n",
        "from load_data import load_financial_news_data, validate_data\n",
        "from load_stock_data import (\n",
        "    load_stock_data,\n",
        "    prepare_stock_data,\n",
        "    validate_stock_data\n",
        ")\n",
        "from date_alignment import (\n",
        "    normalize_dates_to_trading_days,\n",
        "    align_news_and_stock_data,\n",
        "    get_date_alignment_summary\n",
        ")\n",
        "from sentiment_analysis import (\n",
        "    analyze_sentiment_batch,\n",
        "    aggregate_daily_sentiment,\n",
        "    get_sentiment_summary\n",
        ")\n",
        "from correlation_analysis import (\n",
        "    calculate_daily_returns,\n",
        "    calculate_correlation,\n",
        "    analyze_sentiment_returns_correlation,\n",
        "    get_correlation_summary\n",
        ")\n",
        "\n",
        "print(\"All modules imported successfully!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Load Data\n",
        "\n",
        "Load both news data and stock price data.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Configuration\n",
        "NEWS_DATA_PATH = '../data/raw_analyst_ratings.csv'\n",
        "TICKER = 'AAPL'  # Options: AAPL, MSFT, GOOG, META, AMZN, NVDA\n",
        "USE_LOCAL_STOCK_DATA = True\n",
        "STOCK_DATA_DIR = '../data/Data'\n",
        "\n",
        "# Load news data\n",
        "print(f\"Loading news data from {NEWS_DATA_PATH}...\")\n",
        "news_df = load_financial_news_data(NEWS_DATA_PATH)\n",
        "print(f\"✓ Loaded {len(news_df):,} news articles\")\n",
        "print(f\"Date range: {news_df['date'].min()} to {news_df['date'].max()}\")\n",
        "print(f\"Unique stocks: {news_df['stock'].nunique()}\")\n",
        "print(f\"\\nNews data columns: {list(news_df.columns)}\")\n",
        "print(f\"\\nFirst few rows:\")\n",
        "news_df.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Filter news data for selected ticker (optional - can analyze all stocks)\n",
        "if 'stock' in news_df.columns:\n",
        "    news_ticker_df = news_df[news_df['stock'] == TICKER].copy()\n",
        "    print(f\"Filtered to {TICKER}: {len(news_ticker_df):,} articles\")\n",
        "else:\n",
        "    news_ticker_df = news_df.copy()\n",
        "    print(\"No stock filter applied - using all news articles\")\n",
        "\n",
        "# Load stock data\n",
        "print(f\"\\nLoading stock data for {TICKER}...\")\n",
        "stock_df = load_stock_data(\n",
        "    ticker=TICKER,\n",
        "    use_local_data=USE_LOCAL_STOCK_DATA,\n",
        "    data_dir=STOCK_DATA_DIR\n",
        ")\n",
        "print(f\"✓ Loaded {len(stock_df):,} trading days\")\n",
        "print(f\"Date range: {stock_df['date'].min()} to {stock_df['date'].max()}\")\n",
        "print(f\"\\nStock data columns: {list(stock_df.columns)}\")\n",
        "print(f\"\\nFirst few rows:\")\n",
        "stock_df.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Date Alignment\n",
        "\n",
        "Normalize dates to align news articles with trading days. News published on non-trading days (weekends, holidays) will be aligned to the next trading day.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Normalize dates to trading days\n",
        "print(\"Aligning news dates to trading days...\")\n",
        "news_aligned, stock_aligned = normalize_dates_to_trading_days(\n",
        "    news_ticker_df,\n",
        "    stock_df,\n",
        "    news_date_col='date',\n",
        "    stock_date_col='date'\n",
        ")\n",
        "\n",
        "print(f\"✓ News articles after alignment: {len(news_aligned):,}\")\n",
        "print(f\"✓ Trading days: {len(stock_aligned):,}\")\n",
        "\n",
        "# Get alignment summary\n",
        "alignment_summary = get_date_alignment_summary(\n",
        "    news_ticker_df,\n",
        "    stock_df,\n",
        "    news_aligned,  # Using aligned news as reference\n",
        "    news_date_col='date'\n",
        ")\n",
        "\n",
        "print(\"\\nAlignment Summary:\")\n",
        "print(f\"  Original news articles: {alignment_summary['original_news_count']:,}\")\n",
        "print(f\"  Alignment rate: {alignment_summary['alignment_rate']:.2%}\")\n",
        "print(f\"  News date range: {alignment_summary['date_range_news']['min']} to {alignment_summary['date_range_news']['max']}\")\n",
        "print(f\"  Stock date range: {alignment_summary['date_range_stock']['min']} to {alignment_summary['date_range_stock']['max']}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Sentiment Analysis\n",
        "\n",
        "Perform sentiment analysis on news headlines to quantify the tone (positive, negative, neutral).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Perform sentiment analysis on headlines\n",
        "print(\"Performing sentiment analysis on headlines...\")\n",
        "news_with_sentiment = analyze_sentiment_batch(\n",
        "    news_aligned,\n",
        "    text_column='headline',\n",
        "    method='auto',  # Will use best available: TextBlob > VADER > Simple\n",
        "    add_classification=True\n",
        ")\n",
        "\n",
        "print(f\"\\nSentiment Distribution:\")\n",
        "print(news_with_sentiment['sentiment'].value_counts())\n",
        "\n",
        "# Get sentiment summary\n",
        "sentiment_summary = get_sentiment_summary(news_with_sentiment)\n",
        "print(f\"\\nSentiment Statistics:\")\n",
        "print(f\"  Mean sentiment score: {sentiment_summary['mean_sentiment']:.4f}\")\n",
        "print(f\"  Median sentiment score: {sentiment_summary['median_sentiment']:.4f}\")\n",
        "print(f\"  Std deviation: {sentiment_summary['std_sentiment']:.4f}\")\n",
        "print(f\"  Range: [{sentiment_summary['min_sentiment']:.4f}, {sentiment_summary['max_sentiment']:.4f}]\")\n",
        "\n",
        "# Display sample headlines with sentiment\n",
        "print(\"\\nSample headlines with sentiment:\")\n",
        "sample_df = news_with_sentiment[['headline', 'sentiment_score', 'sentiment']].head(10)\n",
        "for idx, row in sample_df.iterrows():\n",
        "    print(f\"\\n[{row['sentiment']:8s}] ({row['sentiment_score']:6.3f}): {row['headline'][:80]}...\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Aggregate daily sentiment scores\n",
        "# If multiple articles appear on the same day, compute average daily sentiment\n",
        "print(\"\\nAggregating daily sentiment scores...\")\n",
        "daily_sentiment = aggregate_daily_sentiment(\n",
        "    news_with_sentiment,\n",
        "    date_column='aligned_date',\n",
        "    sentiment_column='sentiment_score',\n",
        "    aggregation_method='mean'  # Options: 'mean', 'median', 'weighted'\n",
        ")\n",
        "\n",
        "print(f\"✓ Aggregated to {len(daily_sentiment):,} unique trading days\")\n",
        "print(f\"\\nDaily sentiment statistics:\")\n",
        "print(daily_sentiment['daily_sentiment_score'].describe())\n",
        "\n",
        "# Show days with most articles\n",
        "print(\"\\nTop 10 days by article count:\")\n",
        "top_days = daily_sentiment.nlargest(10, 'article_count')[['aligned_date', 'article_count', 'daily_sentiment_score']]\n",
        "print(top_days.to_string(index=False))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Calculate Stock Returns\n",
        "\n",
        "Compute daily percentage changes in stock prices to represent stock movements.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calculate daily returns\n",
        "print(\"Calculating daily stock returns...\")\n",
        "stock_with_returns = calculate_daily_returns(\n",
        "    stock_aligned,\n",
        "    price_column='Close',\n",
        "    date_column='aligned_date',\n",
        "    method='pct_change'  # Options: 'pct_change' or 'log'\n",
        ")\n",
        "\n",
        "print(f\"✓ Calculated returns for {len(stock_with_returns):,} trading days\")\n",
        "print(f\"\\nDaily returns statistics:\")\n",
        "print(stock_with_returns['daily_returns'].describe())\n",
        "\n",
        "# Display sample returns\n",
        "print(\"\\nSample daily returns:\")\n",
        "sample_returns = stock_with_returns[['aligned_date', 'Close', 'daily_returns']].head(10)\n",
        "print(sample_returns.to_string(index=False))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Correlation Analysis\n",
        "\n",
        "Perform statistical correlation analysis between daily sentiment scores and stock returns.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Merge daily sentiment with stock returns\n",
        "print(\"Merging daily sentiment with stock returns...\")\n",
        "correlation_df = pd.merge(\n",
        "    daily_sentiment[['aligned_date', 'daily_sentiment_score', 'article_count']],\n",
        "    stock_with_returns[['aligned_date', 'Close', 'daily_returns']],\n",
        "    on='aligned_date',\n",
        "    how='inner'\n",
        ")\n",
        "\n",
        "print(f\"✓ Merged data: {len(correlation_df):,} days with both sentiment and returns\")\n",
        "print(f\"Date range: {correlation_df['aligned_date'].min()} to {correlation_df['aligned_date'].max()}\")\n",
        "\n",
        "# Display sample merged data\n",
        "print(\"\\nSample merged data:\")\n",
        "correlation_df.head(10)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Perform comprehensive correlation analysis\n",
        "print(\"Performing correlation analysis...\")\n",
        "correlation_result = analyze_sentiment_returns_correlation(\n",
        "    correlation_df,\n",
        "    sentiment_column='daily_sentiment_score',\n",
        "    returns_column='daily_returns',\n",
        "    date_column='aligned_date',\n",
        "    method='pearson'  # Options: 'pearson', 'spearman', 'kendall'\n",
        ")\n",
        "\n",
        "# Display correlation summary\n",
        "print(get_correlation_summary(correlation_result))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Visualization\n",
        "\n",
        "Create visualizations to understand the relationship between sentiment and stock returns.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot 1: Sentiment vs Returns Scatter Plot\n",
        "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
        "fig.suptitle(f'{TICKER} - Sentiment vs Stock Returns Analysis', fontsize=16, fontweight='bold')\n",
        "\n",
        "# Scatter plot: Sentiment vs Returns\n",
        "ax1 = axes[0, 0]\n",
        "ax1.scatter(correlation_df['daily_sentiment_score'], correlation_df['daily_returns'], \n",
        "           alpha=0.5, s=50)\n",
        "ax1.axhline(y=0, color='black', linestyle='--', linewidth=0.5)\n",
        "ax1.axvline(x=0, color='black', linestyle='--', linewidth=0.5)\n",
        "ax1.set_xlabel('Daily Sentiment Score', fontsize=12)\n",
        "ax1.set_ylabel('Daily Returns (%)', fontsize=12)\n",
        "ax1.set_title('Sentiment vs Returns Scatter Plot', fontsize=14)\n",
        "ax1.grid(True, alpha=0.3)\n",
        "\n",
        "# Add correlation line\n",
        "z = np.polyfit(correlation_df['daily_sentiment_score'].dropna(), \n",
        "               correlation_df['daily_returns'].dropna(), 1)\n",
        "p = np.poly1d(z)\n",
        "x_line = np.linspace(correlation_df['daily_sentiment_score'].min(), \n",
        "                     correlation_df['daily_sentiment_score'].max(), 100)\n",
        "ax1.plot(x_line, p(x_line), \"r--\", alpha=0.8, linewidth=2, \n",
        "         label=f'Correlation: {correlation_result[\"correlation\"][\"correlation\"]:.4f}')\n",
        "ax1.legend()\n",
        "\n",
        "# Time series: Sentiment and Returns over time\n",
        "ax2 = axes[0, 1]\n",
        "ax2_twin = ax2.twinx()\n",
        "ax2.plot(correlation_df['aligned_date'], correlation_df['daily_sentiment_score'], \n",
        "         color='blue', alpha=0.7, label='Sentiment Score', linewidth=1)\n",
        "ax2_twin.plot(correlation_df['aligned_date'], correlation_df['daily_returns'], \n",
        "              color='green', alpha=0.7, label='Daily Returns (%)', linewidth=1)\n",
        "ax2.axhline(y=0, color='blue', linestyle='--', linewidth=0.5, alpha=0.5)\n",
        "ax2_twin.axhline(y=0, color='green', linestyle='--', linewidth=0.5, alpha=0.5)\n",
        "ax2.set_xlabel('Date', fontsize=12)\n",
        "ax2.set_ylabel('Sentiment Score', fontsize=12, color='blue')\n",
        "ax2_twin.set_ylabel('Daily Returns (%)', fontsize=12, color='green')\n",
        "ax2.set_title('Sentiment and Returns Over Time', fontsize=14)\n",
        "ax2.tick_params(axis='y', labelcolor='blue')\n",
        "ax2_twin.tick_params(axis='y', labelcolor='green')\n",
        "ax2.grid(True, alpha=0.3)\n",
        "\n",
        "# Distribution: Sentiment scores\n",
        "ax3 = axes[1, 0]\n",
        "ax3.hist(correlation_df['daily_sentiment_score'], bins=50, alpha=0.7, color='blue', edgecolor='black')\n",
        "ax3.axvline(x=0, color='red', linestyle='--', linewidth=2, label='Neutral')\n",
        "ax3.set_xlabel('Daily Sentiment Score', fontsize=12)\n",
        "ax3.set_ylabel('Frequency', fontsize=12)\n",
        "ax3.set_title('Distribution of Daily Sentiment Scores', fontsize=14)\n",
        "ax3.legend()\n",
        "ax3.grid(True, alpha=0.3)\n",
        "\n",
        "# Distribution: Returns\n",
        "ax4 = axes[1, 1]\n",
        "ax4.hist(correlation_df['daily_returns'], bins=50, alpha=0.7, color='green', edgecolor='black')\n",
        "ax4.axvline(x=0, color='red', linestyle='--', linewidth=2, label='Zero Return')\n",
        "ax4.set_xlabel('Daily Returns (%)', fontsize=12)\n",
        "ax4.set_ylabel('Frequency', fontsize=12)\n",
        "ax4.set_title('Distribution of Daily Returns', fontsize=14)\n",
        "ax4.legend()\n",
        "ax4.grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('../outputs/sentiment_returns_correlation.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot 2: Returns by Sentiment Category\n",
        "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
        "fig.suptitle(f'{TICKER} - Returns Analysis by Sentiment Category', fontsize=16, fontweight='bold')\n",
        "\n",
        "# Box plot: Returns by sentiment category\n",
        "ax1 = axes[0]\n",
        "# Create sentiment categories\n",
        "correlation_df['sentiment_category'] = correlation_df['daily_sentiment_score'].apply(\n",
        "    lambda x: 'Positive' if x > 0.1 else ('Negative' if x < -0.1 else 'Neutral')\n",
        ")\n",
        "sentiment_order = ['Negative', 'Neutral', 'Positive']\n",
        "box_data = [correlation_df[correlation_df['sentiment_category'] == cat]['daily_returns'].values \n",
        "            for cat in sentiment_order]\n",
        "bp = ax1.boxplot(box_data, labels=sentiment_order, patch_artist=True)\n",
        "colors = ['red', 'gray', 'green']\n",
        "for patch, color in zip(bp['boxes'], colors):\n",
        "    patch.set_facecolor(color)\n",
        "    patch.set_alpha(0.7)\n",
        "ax1.axhline(y=0, color='black', linestyle='--', linewidth=1)\n",
        "ax1.set_ylabel('Daily Returns (%)', fontsize=12)\n",
        "ax1.set_title('Returns Distribution by Sentiment Category', fontsize=14)\n",
        "ax1.grid(True, alpha=0.3, axis='y')\n",
        "\n",
        "# Bar plot: Average returns by sentiment\n",
        "ax2 = axes[1]\n",
        "avg_returns_by_sentiment = correlation_df.groupby('sentiment_category')['daily_returns'].mean()\n",
        "colors_bar = ['red' if x < 0 else 'green' for x in avg_returns_by_sentiment.values]\n",
        "bars = ax2.bar(avg_returns_by_sentiment.index, avg_returns_by_sentiment.values, \n",
        "               color=colors_bar, alpha=0.7, edgecolor='black')\n",
        "ax2.axhline(y=0, color='black', linestyle='--', linewidth=1)\n",
        "ax2.set_ylabel('Average Daily Returns (%)', fontsize=12)\n",
        "ax2.set_title('Average Returns by Sentiment Category', fontsize=14)\n",
        "ax2.grid(True, alpha=0.3, axis='y')\n",
        "# Add value labels on bars\n",
        "for bar in bars:\n",
        "    height = bar.get_height()\n",
        "    ax2.text(bar.get_x() + bar.get_width()/2., height,\n",
        "             f'{height:.3f}%',\n",
        "             ha='center', va='bottom' if height > 0 else 'top', fontsize=10)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('../outputs/returns_by_sentiment.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. KPIs: Sentiment Analysis and Correlation Strength\n",
        "\n",
        "Calculate Key Performance Indicators for:\n",
        "1. **Proactivity to self-learn** - sharing references\n",
        "2. **Sentiment Analysis** - accuracy and coverage\n",
        "3. **Correlation Strength** - statistical significance and magnitude\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calculate KPIs\n",
        "print(\"=\" * 70)\n",
        "print(\"KEY PERFORMANCE INDICATORS (KPIs)\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# KPI 1: Sentiment Analysis Coverage\n",
        "total_news = len(news_ticker_df)\n",
        "analyzed_news = len(news_with_sentiment)\n",
        "sentiment_coverage = (analyzed_news / total_news * 100) if total_news > 0 else 0\n",
        "\n",
        "print(\"\\n1. SENTIMENT ANALYSIS KPIs:\")\n",
        "print(f\"   • Total news articles: {total_news:,}\")\n",
        "print(f\"   • Articles analyzed: {analyzed_news:,}\")\n",
        "print(f\"   • Coverage rate: {sentiment_coverage:.2f}%\")\n",
        "print(f\"   • Sentiment distribution:\")\n",
        "for sentiment, count in news_with_sentiment['sentiment'].value_counts().items():\n",
        "    pct = (count / analyzed_news * 100) if analyzed_news > 0 else 0\n",
        "    print(f\"     - {sentiment:8s}: {count:6,} ({pct:5.2f}%)\")\n",
        "\n",
        "# KPI 2: Date Alignment Quality\n",
        "alignment_rate = alignment_summary['alignment_rate']\n",
        "print(f\"\\n2. DATE ALIGNMENT KPIs:\")\n",
        "print(f\"   • Alignment rate: {alignment_rate:.2%}\")\n",
        "print(f\"   • Days with aligned data: {len(correlation_df):,}\")\n",
        "\n",
        "# KPI 3: Correlation Strength\n",
        "corr_coef = correlation_result['correlation']['correlation']\n",
        "p_value = correlation_result['correlation']['p_value']\n",
        "is_significant = correlation_result['correlation']['is_significant']\n",
        "sample_size = correlation_result['correlation']['sample_size']\n",
        "\n",
        "# Interpret correlation strength\n",
        "abs_corr = abs(corr_coef)\n",
        "if abs_corr < 0.1:\n",
        "    strength = \"Negligible\"\n",
        "elif abs_corr < 0.3:\n",
        "    strength = \"Weak\"\n",
        "elif abs_corr < 0.5:\n",
        "    strength = \"Moderate\"\n",
        "elif abs_corr < 0.7:\n",
        "    strength = \"Strong\"\n",
        "else:\n",
        "    strength = \"Very Strong\"\n",
        "\n",
        "direction = \"Positive\" if corr_coef > 0 else \"Negative\"\n",
        "\n",
        "print(f\"\\n3. CORRELATION STRENGTH KPIs:\")\n",
        "print(f\"   • Correlation coefficient: {corr_coef:.4f}\")\n",
        "print(f\"   • Correlation strength: {strength} ({direction})\")\n",
        "print(f\"   • P-value: {p_value:.6f}\")\n",
        "print(f\"   • Statistically significant: {'Yes' if is_significant else 'No'} (α=0.05)\")\n",
        "print(f\"   • Sample size: {sample_size:,} days\")\n",
        "\n",
        "# KPI 4: Returns by Sentiment\n",
        "if 'sentiment_statistics' in correlation_result:\n",
        "    stats = correlation_result['sentiment_statistics']\n",
        "    print(f\"\\n4. RETURNS BY SENTIMENT KPIs:\")\n",
        "    print(f\"   • Positive sentiment days: {stats['positive_days']:,}\")\n",
        "    print(f\"     Average returns: {stats['avg_returns_positive_sentiment']:.4f}%\")\n",
        "    print(f\"   • Negative sentiment days: {stats['negative_days']:,}\")\n",
        "    print(f\"     Average returns: {stats['avg_returns_negative_sentiment']:.4f}%\")\n",
        "    print(f\"   • Neutral sentiment days: {stats['neutral_days']:,}\")\n",
        "    print(f\"     Average returns: {stats['avg_returns_neutral_sentiment']:.4f}%\")\n",
        "\n",
        "# KPI 5: Data Quality\n",
        "print(f\"\\n5. DATA QUALITY KPIs:\")\n",
        "print(f\"   • News data completeness: {news_ticker_df['headline'].notna().sum() / len(news_ticker_df) * 100:.2f}%\")\n",
        "print(f\"   • Stock data completeness: {stock_df['Close'].notna().sum() / len(stock_df) * 100:.2f}%\")\n",
        "print(f\"   • Merged data completeness: {correlation_df[['daily_sentiment_score', 'daily_returns']].notna().all(axis=1).sum() / len(correlation_df) * 100:.2f}%\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 70)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
